{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "# 1. Load the dataset\n",
    "df=pd.read_csv('..\\\\data\\\\fraud.csv', index_col = 0)\n",
    "# print(df.columns)\n",
    "#Update the DataFrame df by keeping all rows and dropping the first column.\n",
    "#Explanation:\n",
    "# df.iloc is used to access rows and columns by position (not by labels).\n",
    "# : means all rows.\n",
    "# 1: means columns from position 1 to the end.\n",
    "# Column index 0 is the first column, so this skips the first column.\n",
    "df = df.iloc[:,1:]\n",
    "# print(df.columns)\n",
    "y = df['Class'].values\n",
    "\n",
    "X = df.drop(columns = 'Class').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21693, 29) (21693,)\n",
      "Class\n",
      "0        21337\n",
      "1          356\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    98.358918\n",
       "1     1.641082\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (rows, columns)\n",
    "print(X.shape, y.shape)\n",
    "# 2. checking the null value contain in the dataset or not\n",
    "# df.info()\n",
    "# print(\"--------------------------------\")\n",
    "# print(df.isnull().sum())\n",
    "# print(\"--------------------------------\")\n",
    "\n",
    "# print(df.columns)\n",
    "# print(df.isnull().sum())\n",
    "print(df[['Class']].value_counts())\n",
    "df['Class'].value_counts(normalize=True) * 100\n",
    "#data is imbalance 98% not fraud, 2% fraud trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "#60% training data and 40% testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                    test_size = 0.40, \n",
    "                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Confusion Matrix Definition [[TN FP] [FN TP]]\n",
    "\n",
    "True Negative (TN): Actual = 0, Predicted = 0 → Correctly predicted not fraud\n",
    "\n",
    "False Positive (FP): Actual = 0, Predicted = 1 → Predicted fraud, but it’s not (false alarm)\n",
    "\n",
    "False Negative (FN): Actual = 1, Predicted = 0 → Missed a fraud case! ❌\n",
    "\n",
    "True Positive (TP): Actual = 1, Predicted = 1 → Correctly predicted fraud ✅\n",
    "\n",
    "Why It Matters in Fraud Detection FP (False Positive): Inconvenience to a customer (e.g., transaction blocked)\n",
    "\n",
    "FN (False Negative): Very dangerous — fraud not caught!\n",
    "\n",
    "So in fraud detection:\n",
    "\n",
    "Recall (how many actual frauds you caught) is very important.\n",
    "\n",
    "You want to minimize FN, even at the cost of a few extra FPs.\n",
    "\n",
    "             Predicted\n",
    "            0       1\n",
    "Actual 0 [TN FP] 1 [FN TP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Naive Bayes classification report\n",
      "Consufion Matrix:  [[8349, 192], [19, 118]]\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      8541\n",
      "           1       0.38      0.86      0.53       137\n",
      "\n",
      "    accuracy                           0.98      8678\n",
      "   macro avg       0.69      0.92      0.76      8678\n",
      "weighted avg       0.99      0.98      0.98      8678\n",
      "\n",
      "GNB ROC-AUC: 0.9712558658664049\n"
     ]
    }
   ],
   "source": [
    "# ---- GAUSSIAN NB --------------------------------------------------\n",
    "# works on continuous / numeric features (assumes Gaussian distribution)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "gnb_mat_clf = confusion_matrix(y_test, y_pred_gnb)\n",
    "gnb_report_clf = classification_report(y_test, y_pred_gnb)\n",
    "print(\"GNB Naive Bayes classification report\")\n",
    "print(\"Consufion Matrix: \",gnb_mat_clf.tolist())\n",
    "print(\"Classification Report \")\n",
    "print(gnb_report_clf)\n",
    "\n",
    "# predict probabilities\n",
    "# [:,1] means \"probability of the positive class\"\n",
    "y_probs = gnb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# calculate roc_auc\n",
    "gnb_auc_score = roc_auc_score(y_test, y_probs)\n",
    "print(\"GNB ROC-AUC:\", gnb_auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- MULTINOMIAL NB ----------------------------------------------\n",
    "# works on count-based features (e.g. Bag-of-Words)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB(alpha=1.0)\n",
    "#Multinomial Naïve Bayes classifiers due to this fraud dataset values are negative and continuous date that not supported.\n",
    "# mnb.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_mnb = mnb.predict(X_test)\n",
    "\n",
    "# mnb_precision = precision_score(y_test, y_pred_mnb)\n",
    "# mnb_recall = recall_score(y_test, y_pred_mnb)\n",
    "\n",
    "# print(\"MultinomialNB -> Precision:\", mnb_precision, \", Recall:\", mnb_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB Naive Bayes classification report\n",
      "Consufion Matrix:  [[8533, 8], [33, 104]]\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8541\n",
      "           1       0.93      0.76      0.84       137\n",
      "\n",
      "    accuracy                           1.00      8678\n",
      "   macro avg       0.96      0.88      0.92      8678\n",
      "weighted avg       1.00      1.00      1.00      8678\n",
      "\n",
      "BNB ROC-AUC: 0.9551925149365406\n"
     ]
    }
   ],
   "source": [
    "# ---- BERNOUILLI NB ------------------------------------------------\n",
    "# works on binary (0/1) features only\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB(alpha=1.0)\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "\n",
    "bnb_mat_clf = confusion_matrix(y_test, y_pred_bnb)\n",
    "bnb_report_clf = classification_report(y_test, y_pred_bnb)\n",
    "print(\"BNB Naive Bayes classification report\")\n",
    "print(\"Consufion Matrix: \",bnb_mat_clf.tolist())\n",
    "print(\"Classification Report \")\n",
    "print(bnb_report_clf)\n",
    "\n",
    "# predict probabilities\n",
    "# [:,1] means \"probability of the positive class\"\n",
    "y_probs = bnb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# calculate roc_auc\n",
    "bnb_auc_score = roc_auc_score(y_test, y_probs)\n",
    "print(\"BNB ROC-AUC:\", bnb_auc_score)\n",
    "\n",
    "# bnb_precision = precision_score(y_test, y_pred_bnb)\n",
    "# bnb_recall = recall_score(y_test, y_pred_bnb)\n",
    "\n",
    "# print(\"BernoulliNB  -> Precision:\", bnb_precision, \", Recall:\", bnb_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
